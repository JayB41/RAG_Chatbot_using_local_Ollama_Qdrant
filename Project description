Project Description
With my first project, I built an open-source local system that allows you to use a model of your choice to access 
and retrieve knowledge from your own database. This database can be continuously enriched with your personal knowledge base, 
enabling a dynamic and adaptive information system.
One of the core functionalities is the ability to transform information from PDF files into a structured format. 
The system extracts both text and images, converting them into vector embeddings for efficient retrieval. 
To achieve this, I utilized PyMuPDF for PDF extraction and Sentence Transformers for embedding generation.
The architecture is designed to be highly modular, ensuring that integrating a new model is straightforward and efficient. 
This modular approach also facilitates easy maintenance and scalability, 
making the system adaptable to future advancements in model architectures and data processing techniques.

Utilizing Ollama and Model Flexibility
A key component of this project is the integration with Ollama, a powerful and flexible 
command-line interface that allows seamless interaction with various language models. 
This enables the system to leverage state-of-the-art models for generating accurate and contextually relevant responses.
Currently, the system supports the following models through Ollama:
LLaMA 3.2: Used for generating coherent and context-aware text responses.
DeepSeek: Designed for advanced information retrieval and synthesis, ensuring precise and relevant answers.
Ollama is utilized for model management and execution, allowing the system to switch between models effortlessly. 
This flexibility ensures that the system can be easily adapted to different use cases and requirements 
by simply changing the model configuration.

Extensibility and Future Development
This setup is highly extensible and can be expanded in various directions and application areas, including:
Support for additional data types: Enhancing the system to process other file formats such as Word documents, 
CSVs, or even multimedia content.
Advanced data extraction techniques: Implementing more sophisticated methods, 
including optical character recognition (OCR) for images and tables.
Improved performance and scalability: Optimizing vector search efficiency with Qdrant, 
enabling faster and more accurate retrieval.
Integration with AI agent systems: Creating a more complex infrastructure to support autonomous agent interactions 
and advanced reasoning capabilities.
The modular design not only supports these extensions but also encourages community contributions and collaborations, 
making it a flexible platform for ongoing development.


Acknowledgements and Inspirations
I want to emphasize that I did not invent anything new, and I am unsure if anyone will actually read this. 
However, I genuinely want to thank the LinkedIn community that I follow, as they consistently share valuable knowledge and 
insights, making it easier for beginners like me to learn and grow.
For this project, I took inspiration from the following GitHub repository:
https://github.com/patchy631/ai-engineering-hub/tree/mains
If you are looking to build something more advanced or professional, I highly recommend following this work. 
For me, the goal of this project was to create a foundational system as the first addition to my personal portfolio, 
ensuring that it runs correctly and efficiently.

Summary
This open-source system is designed to leverage cutting-edge models like LLaMA 3.2 and DeepSeek for knowledge retrieval, 
using Ollama for flexible model management. 
It features a modular and scalable architecture that makes it easy to integrate new models and functionalities, 
ensuring adaptability to evolving AI technologies. The project serves as a foundation for building more complex systems, 
including AI agent frameworks and advanced information retrieval solutions.


For the folder structure in my project environment, I have organized it as follows:
 

├── data/                       # Data management and storage
│   ├── input/                	    # Input files (e.g., PDFs)
│   ├── processed/                  # Processed files (e.g., extracted text)
│   └── qdrant_db/            	    # Local Qdrant vector database
│       └── qdrant_local.db    		      # Main database file
│
├── scripts/                    # script folder
│   ├── load_data.py/                # Data processing and embedding generation
│   ├── chat_interface/              # Streamlit-based chat and interaction interface
